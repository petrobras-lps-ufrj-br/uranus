![Uranus CI](https://github.com/petrobras-lps-ufrj-br/uranus/actions/workflows/ci.yml/badge.svg)


# ğŸª Uranus


Welcome to **Uranus**! This project is a modular framework designed for developing, training, and testing artificial intelligence models, with a strong focus on **Time Series Forecasting** using **PyTorch** and **PyTorch Lightning**.

## ğŸ¯ Purpose

The goal of **Uranus** is to provide a clean, extensible structure for end-to-end AI workflows. Beyond model development, it serves as a comprehensive framework for orquestrating jobs (via **Airflow**) that collect data from **Cognite**, process it through high-performance inference servers like **NVIDIA Triton**, and visualize results in real-time. 

It abstracts away common boilerplate code for data loading, preprocessing, and training loops, allowing researchers and developers to focus on model architecture and feature engineering while maintaining a production-ready deployment path.

---

## ğŸ“‚ Repository Structure

The codebase is organized into a main package named `uranus`, with sub-packages for AI and visualization:

```text
.
â”œâ”€â”€ ğŸ“‚ uranus/              # Main project package
â”‚   â”œâ”€â”€ ğŸ“‚ ai/              # AI and Machine Learning core
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ callbacks/   # Custom PyTorch Lightning callbacks
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ clients/     # External API clients (e.g., Cognite)
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ evaluation/  # Metrics and model evaluation tools
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ loaders/     # Custom DataLoaders (e.g., Time Series Windowing)
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ models/      # PyTorch Model architectures (e.g., MLP)
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ preprocessing/ # Sktime & Sklearn pipelines
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ runners/     # Scripts to execute training/inference jobs
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ trainers/    # Training loops (Cross-Validation + Lightning)
â”‚   â”‚   â””â”€â”€ ğŸ“‚ visualization/ # Training and inference visualization tools
â”‚   â””â”€â”€ ğŸ“‚ display/         # Visualization and dashboard tools
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/           # Jupyter Notebooks for exploration and demos
â”œâ”€â”€ ğŸ“‚ scripts/             # Helper scripts
â”œâ”€â”€ ğŸ“œ activate.sh          # Environment setup script
â”œâ”€â”€ ğŸ“œ Makefile             # Shortcuts for installation and running
â””â”€â”€ ğŸ“œ requirements.txt     # Python dependencies
```

---

## âœ¨ Key Features

*   **âš¡ PyTorch Lightning Integration**: Robust training loops with built-in logging, checkpointing, and GPU support.
*   **ğŸ”„ Automated Cross-Validation**: The `Time Series Trainer` handles CV splits (e.g., TimeSeriesSplit) automatically and aggregates metrics.
*   **ğŸ“Š Rich Logging & Evaluation**: 
    *   Beautiful ASCII metric tables and emoji-enhanced logs.
    *   Automatic collection of training and validation loss history.
    *   Custom `ModelCheckpoint` that saves model state, weights, and detailed history.
*   **ğŸ›  Advanced Preprocessing**: Modular pipelines using `sktime` and `sklearn` for easy feature engineering (e.g., Lag features, Standard Scaling).
*   **ğŸ§µ Custom DataLoaders**: Flexible loaders that accept raw dataframes and handle windowing and batching on-the-fly.
*   **ğŸ§ª CI Test**: Automatic validation of module imports and package integrity on every push.

---

## ğŸš€ Getting Started

### Prerequisites

*   **OS**: Mac/Linux
*   **Tools**: `make`, `python3`, `virtualenv`

### Installation

To set up the environment and install dependencies, simply run:

```bash
make
```

This command will source `activate.sh`, create a virtual environment in `.uranus-env` (if it doesn't exist), and install the required packages.

### ğŸ““ Running Notebooks

To launch a Jupyter Lab instance with the environment pre-configured:

```bash
make jupyter
```

---

## ğŸƒ Running Training Jobs

The repository provides a versatile script `scripts/job_v1.py` to run training jobs. It supports command-line arguments and JSON configuration files.

### Command Line Arguments

| Argument | Flag | Description | Default |
| :--- | :--- | :--- | :--- |
| `csv_path` | `--path`, `-p` | Path to the input CSV file (Required) | `None` |
| `fold` | `--fold`, `-f` | Specific fold index to train (Optional). If not set, trains all folds. | `None` |
| `epochs` | `--epochs`, `-e` | Number of training epochs | `20` |
| `splits` | `--splits`, `-s` | Number of Time Series Cross-Validation splits | `10` |
| `job_json` | `--job_json`, `-j` | Path to a JSON configuration file (Optional) | `None` |

### Examples

**1. Basic Run:**
Train on all folds using a specific CSV file.

```bash
python3 scripts/job_v1.py -p data/compressor.csv
```

**2. Train Specific Fold:**
Train only the 3rd fold with 50 epochs.

```bash
python3 scripts/job_v1.py -p data/compressor.csv -f 3 -e 50
```

**3. Custom Splits:**
Train with 5 cross-validation splits.

```bash
python3 scripts/job_v1.py -p data/compressor.csv -s 5
```

**4. Using a JSON Config:**
You can define your job parameters in a `job.json` file:

```json
{
    "csv_path": "data/dataset.csv",
    "fold": 0,
    "epochs": 100,
    "splits": 5
}
```

Then run it:

```bash
python3 scripts/job_v1.py -j job.json
```

---

## ğŸ“¡ In-Production Inference (Triton)

**Uranus** integrates with **NVIDIA Triton Inference Server** for high-performance model serving. 

### ğŸ— Model Repository

Models should be placed in the `data/model_repository/` directory following this schema:

```text
data/model_repository/
â””â”€â”€ <model_name>/
    â”œâ”€â”€ config.pbtxt        # Model configuration
    â””â”€â”€ 1/                  # Version number
        â””â”€â”€ model.pt        # Model file
```

For more details, see [data/model_repository/README.md](data/model_repository/README.md).

### ğŸ³ Deployment

To start the full stack (Database, Grafana, InfluxDB, and Triton):

```bash
docker-compose up -d
```

---

## ğŸ–¥ Display & Visualization

The `uranus.display` module provides a powerful, configurable dashboard for real-time monitoring and data interaction.

### ğŸ“Š Key Capabilities

*   **ğŸ“ˆ Time Series Visualization**: Interactive plots to monitor sensor data, model inputs, and forecasting results.
*   **ğŸš¨ Alarm System**: Configurable threshold-based alarms to notify users of anomalies or performance degradation.
*   **âš™ï¸ Configurable Server**: A flexible FastAPI backend that serves as the integration point for data collection and visualization.
*   **ğŸ›  Model Adaptation**: Tools to visualize model drift and facilitate manual or automated adjustments to the inference pipeline.

For detailed configuration, see the [uranus/display/README.md](uranus/display/README.md).

---

## ğŸ›  Python Usage Example

Here is a simplified example of how to set up a training pipeline programmatically using the `uranus` modules:

```python
import os
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sktime.transformations.compose import TransformerPipeline
from uranus.ai.loaders import DataLoader_v1
from uranus.ai.models import Model_v1
from uranus.ai.trainers.time_series import Trainer
from uranus.ai.preprocessing import Lag

# 1. Define Data & Features
features = {
    "input_1": "Raw_Sensor_1", 
    "target": "Raw_Target"
}
input_names = ["input_1"]
lags = {
    "input_1": Lag(10), 
    "target": Lag(-1)
}
preprocessors = {
    "input_1": TransformerPipeline([("scaler", StandardScaler())]),
    "target": TransformerPipeline([("scaler", StandardScaler())])
}

# 2. Initialize DataLoader
dataset = DataLoader_v1(
    path="data.csv",
    features=features,
    input_features=input_names,
    target_feature="target",
    lags=lags, 
    preprocessors=preprocessors
)

# 3. Setup Model & Trainer
model = Model_v1(dataset=dataset, n_hidden=32)
trainer = Trainer(
    model=model,
    cv_strategy=TimeSeriesSplit(n_splits=4),
    accelerator='auto'
)

# 4. Train
# Returns a list of results (metrics & history) for each fold
trainer.fit(dataset, num_epochs=10)

# 5. Access History
print(results[0].history['val_loss'])
```

---

## ğŸ¤ Contributing

Feel free to open issues or submit pull requests. Ensure all new modules have appropriate unit tests and follow the existing directory structure.
